{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing viewed_posts...\n",
      "Fetching data from /posts/view, page 1...\n",
      "Fetching data from /posts/view, page 2...\n",
      "Fetching data from /posts/view, page 3...\n",
      "Fetching data from /posts/view, page 4...\n",
      "Fetching data from /posts/view, page 5...\n",
      "Fetching data from /posts/view, page 6...\n",
      "Fetching data from /posts/view, page 7...\n",
      "Fetching data from /posts/view, page 8...\n",
      "No more data to fetch.\n",
      "Data saved to viewed_posts.csv\n",
      "Processing liked_posts...\n",
      "Fetching data from /posts/like, page 1...\n",
      "Fetching data from /posts/like, page 2...\n",
      "Fetching data from /posts/like, page 3...\n",
      "No more data to fetch.\n",
      "Data saved to liked_posts.csv\n",
      "Processing inspired_posts...\n",
      "Fetching data from /posts/inspire, page 1...\n",
      "Fetching data from /posts/inspire, page 2...\n",
      "No more data to fetch.\n",
      "Data saved to inspired_posts.csv\n",
      "Processing rated_posts...\n",
      "Fetching data from /posts/rating, page 1...\n",
      "Fetching data from /posts/rating, page 2...\n",
      "Fetching data from /posts/rating, page 3...\n",
      "Fetching data from /posts/rating, page 4...\n",
      "No more data to fetch.\n",
      "Data saved to rated_posts.csv\n",
      "Processing all_posts...\n",
      "Fetching data from /posts/summary/get, page 1...\n",
      "Fetching data from /posts/summary/get, page 2...\n",
      "Fetching data from /posts/summary/get, page 3...\n",
      "No more data to fetch.\n",
      "Data saved to all_posts.csv\n",
      "Processing all_users...\n",
      "Fetching data from /users/get_all, page 1...\n",
      "Fetching data from /users/get_all, page 2...\n",
      "Fetching data from /users/get_all, page 3...\n",
      "No more data to fetch.\n",
      "Data saved to all_users.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API Configuration\n",
    "BASE_URL = \"https://api.socialverseapp.com\"\n",
    "HEADERS = {\n",
    "    \"Flic-Token\": \"flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8\"\n",
    "}\n",
    "PAGE_SIZE = 1000  # Maximum page size\n",
    "\n",
    "# Endpoints and corresponding filenames\n",
    "ENDPOINTS = {\n",
    "    \"viewed_posts\": \"/posts/view\",\n",
    "    \"liked_posts\": \"/posts/like\",\n",
    "    \"inspired_posts\": \"/posts/inspire\",\n",
    "    \"rated_posts\": \"/posts/rating\",\n",
    "    \"all_posts\": \"/posts/summary/get\",\n",
    "    \"all_users\": \"/users/get_all\"\n",
    "}\n",
    "\n",
    "FILENAMES = {\n",
    "    \"viewed_posts\": \"viewed_posts.csv\",\n",
    "    \"liked_posts\": \"liked_posts.csv\",\n",
    "    \"inspired_posts\": \"inspired_posts.csv\",\n",
    "    \"rated_posts\": \"rated_posts.csv\",\n",
    "    \"all_posts\": \"all_posts.csv\",\n",
    "    \"all_users\": \"all_users.csv\"\n",
    "}\n",
    "\n",
    "# Fetch data from a single API endpoint\n",
    "def fetch_data(endpoint):\n",
    "    page = 1\n",
    "    all_data = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"page\": page,\n",
    "            \"page_size\": PAGE_SIZE,\n",
    "            \"resonance_algorithm\": \"resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "        }\n",
    "        response = requests.get(f\"{BASE_URL}{endpoint}\", headers=HEADERS, params=params)\n",
    "        print(f\"Fetching data from {endpoint}, page {page}...\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            records = data.get(\"posts\", []) or data.get(\"users\", [])\n",
    "            if not records:\n",
    "                print(\"No more data to fetch.\")\n",
    "                break\n",
    "\n",
    "            all_data.extend(records)\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Save data to a CSV file\n",
    "def save_to_csv(data, filename, fieldnames):\n",
    "    if not data:\n",
    "        print(f\"No data to save for {filename}.\")\n",
    "        return\n",
    "\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Main function to fetch and save data from all APIs\n",
    "def fetch_and_save_all_data():\n",
    "    for key, endpoint in ENDPOINTS.items():\n",
    "        print(f\"Processing {key}...\")\n",
    "\n",
    "        # Fetch data\n",
    "        data = fetch_data(endpoint)\n",
    "\n",
    "        # Determine fieldnames dynamically from the first record\n",
    "        fieldnames = data[0].keys() if data else []\n",
    "        save_to_csv(data, FILENAMES[key], fieldnames)\n",
    "\n",
    "# Run the script\n",
    "fetch_and_save_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Fetching page 4...\n",
      "Fetching page 5...\n",
      "Fetching page 6...\n",
      "Fetching page 7...\n",
      "Fetching page 8...\n",
      "No more data to fetch.\n",
      "Data saved to viewed_posts.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API Configuration\n",
    "BASE_URL = \"https://api.socialverseapp.com\"\n",
    "ENDPOINT = \"/posts/view\"\n",
    "HEADERS = {\n",
    "    \"Flic-Token\": \"flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8\"\n",
    "}\n",
    "PAGE_SIZE = 1000  # Maximum page size\n",
    "\n",
    "def fetch_data():\n",
    "    page = 1\n",
    "    all_posts = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"page\": page,\n",
    "            \"page_size\": PAGE_SIZE,\n",
    "            \"resonance_algorithm\": \"resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "        }\n",
    "        response = requests.get(f\"{BASE_URL}{ENDPOINT}\", headers=HEADERS, params=params)\n",
    "        print(f\"Fetching page {page}...\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            posts = data.get(\"posts\", [])\n",
    "            if not posts:\n",
    "                print(\"No more data to fetch.\")\n",
    "                break\n",
    "\n",
    "            all_posts.extend(posts)\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "    return all_posts\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    # Define the CSV file structure based on the response data\n",
    "    fieldnames = [\"id\", \"post_id\", \"user_id\", \"viewed_at\"]\n",
    "\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Fetch the data and save it to a CSV file\n",
    "data = fetch_data()\n",
    "save_to_csv(data, \"viewed_posts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "No more data to fetch.\n",
      "Data saved to liked_posts.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# API Configuration\n",
    "BASE_URL = \"https://api.socialverseapp.com\"\n",
    "ENDPOINT = \"/posts/like\"  # Updated for liked posts\n",
    "HEADERS = {\n",
    "    \"Flic-Token\": \"flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8\"\n",
    "}\n",
    "PAGE_SIZE = 1000  # Maximum page size\n",
    "\n",
    "def fetch_liked_posts():\n",
    "    page = 1\n",
    "    all_posts = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"page\": page,\n",
    "            \"page_size\": PAGE_SIZE,\n",
    "            \"resonance_algorithm\": \"resonance_algorithm_cjsvervb7dbhss8bdrj89s44jfjdbsjd0xnjkbvuire8zcjwerui3njfbvsujc5if\"\n",
    "        }\n",
    "        response = requests.get(f\"{BASE_URL}{ENDPOINT}\", headers=HEADERS, params=params)\n",
    "        print(f\"Fetching page {page}...\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            posts = data.get(\"posts\", [])\n",
    "            if not posts:\n",
    "                print(\"No more data to fetch.\")\n",
    "                break\n",
    "\n",
    "            all_posts.extend(posts)\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "    return all_posts\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    # Define the CSV file structure based on the response data\n",
    "    fieldnames = [\"id\", \"post_id\", \"user_id\", \"liked_at\"]  # Updated for liked posts\n",
    "\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Fetch the liked posts and save them to a CSV file\n",
    "data = fetch_liked_posts()\n",
    "save_to_csv(data, \"liked_posts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paune 14 by sade 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
